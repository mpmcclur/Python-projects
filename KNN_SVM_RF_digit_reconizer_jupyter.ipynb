{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Matt\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data using pandas\n",
    "digit_train = pd.read_csv('Kaggle-digit-train.csv')\n",
    "# Dimension of data\n",
    "digit_train.shape\n",
    "digit_train.describe()\n",
    "# Split-out validation dataset\n",
    "array = digit_train.values\n",
    "X = digit_train.drop(['label'],axis=1)\n",
    "Y = digit_train['label']\n",
    "# One-third of data as a part of test set\n",
    "validation_size = 0.33\n",
    "seed = 10\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model using k=14\n",
    "# https://scikit-learn.org/stable/modules/neighbors.html\n",
    "seed = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=14)\n",
    "# fit the model\n",
    "knn.fit(X_train,Y_train)\n",
    "# predict\n",
    "y_pred_knn = knn.predict(X_validation)\n",
    "# accuracy score\n",
    "accuracy_train_knn = accuracy_score(Y_train,knn.predict(X_train))\n",
    "accuracy_validation_knn = accuracy_score(Y_validation,y_pred_knn)\n",
    "accuracy_train_knn # 88% accuracy predicting the variables\n",
    "accuracy_validation_knn # 89% accuracy predicting the outcome (\"label\")\n",
    "print(confusion_matrix(Y_validation,y_pred_knn)) \n",
    "print(classification_report(Y_validation,y_pred_knn)) # 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use this on the real test dataset.\n",
    "digit_test = pd.read_csv('Kaggle-digit-test.csv')\n",
    "digit_y_test = digit_test.drop(['label'],axis=1)\n",
    "pred_test_knn = knn.predict(digit_y_test)\n",
    "pred_test_knn = pd.DataFrame(pred_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model\n",
    "# https://scikit-learn.org/stable/modules/svm.html\n",
    "svclassifier = SVC(kernel='linear')\n",
    "# fit the model\n",
    "svclassifier.fit(X_train, Y_train)\n",
    "# predict\n",
    "y_pred_svm = svclassifier.predict(X_validation)\n",
    "# accuracy score\n",
    "accuracy_train_svm = accuracy_score(Y_train,svclassifier.predict(X_train))\n",
    "accuracy_validation_svm = accuracy_score(Y_validation,y_pred_svm)\n",
    "print(confusion_matrix(Y_validation,y_pred_svm))\n",
    "print(classification_report(Y_validation,y_pred_svm)) # 89% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel SVM Model\n",
    "# Normal SVM is used to find linearly separable data; kernel SVM considers higher dimensions for this separability; it's more complex.\n",
    "# first, we'll try the polynomial kernel\n",
    "k_svclassifier_poly = SVC(kernel='poly', degree=8)  \n",
    "k_svclassifier_poly.fit(X_train, Y_train)  \n",
    "# predict\n",
    "y_pred_k_svm = k_svclassifier_poly.predict(X_validation)\n",
    "# accuracy score\n",
    "accuracy_train_k_svm = accuracy_score(Y_train,k_svclassifier_poly.predict(X_train))\n",
    "accuracy_validation_svm = accuracy_score(Y_validation,y_pred_k_svm)\n",
    "print(confusion_matrix(Y_validation,y_pred_k_svm))\n",
    "print(classification_report(Y_validation,y_pred_k_svm)) # 77% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, we'll try the Gaussian kernel\n",
    "k_svclassifier_gauss = SVC(kernel='rbf')\n",
    "k_svclassifier_gauss.fit(X_train, Y_train)  \n",
    "# predict\n",
    "y_pred_k_svm = k_svclassifier_gauss.predict(X_validation)\n",
    "# accuracy score\n",
    "accuracy_train_k_svm = accuracy_score(Y_train,k_svclassifier_gauss.predict(X_train))\n",
    "accuracy_validation_svm = accuracy_score(Y_validation,y_pred_k_svm)\n",
    "print(confusion_matrix(Y_validation,y_pred_k_svm))\n",
    "print(classification_report(Y_validation,y_pred_k_svm)) # 1% accuracy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third, we'll try the sigmoid kernel\n",
    "k_svclassifier_sig = SVC(kernel='sigmoid') \n",
    "k_svclassifier_sig.fit(X_train, Y_train)  \n",
    "# predict\n",
    "y_pred_k_svm = k_svclassifier_sig.predict(X_validation)\n",
    "# accuracy score\n",
    "accuracy_train_k_svm = accuracy_score(Y_train,k_svclassifier_sig.predict(X_train))\n",
    "accuracy_validation_svm = accuracy_score(Y_validation,y_pred_k_svm)\n",
    "print(confusion_matrix(Y_validation,y_pred_k_svm))\n",
    "print(classification_report(Y_validation,y_pred_k_svm)) # 1% accuracy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "# 200 trees\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=0) # random_state is random generator number, if blank, then uses np.random generator\n",
    "rf.fit(X_train, Y_train)\n",
    "# predict\n",
    "y_pred_rf = rf.predict(X_validation)\n",
    "# accuracy score\n",
    "accuracy_train_rf = accuracy_score(Y_train,rf.predict(X_train))\n",
    "accuracy_validation_rf = accuracy_score(Y_validation,y_pred_rf)\n",
    "print(confusion_matrix(Y_validation,y_pred_rf))\n",
    "print(classification_report(Y_validation,y_pred_rf)) # 91% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use this on the real test dataset.\n",
    "pred_test_rf = RandomForestClassifier.predict(digit_y_test)\n",
    "pred_test_rf = pd.DataFrame(pred_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# side note, we can use random forest for regression as well\n",
    "rf_regression = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "rf_regression.fit(X_train, Y_train)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(Y_validation, y_pred_rf))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(Y_validation, y_pred_rf))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_validation, y_pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of all the algorithms we used, random forest provided the most accurate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
